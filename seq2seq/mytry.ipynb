{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import helper\n",
    "\n",
    "source_path = 'data/letters_source.txt'\n",
    "target_path = 'data/letters_target.txt'\n",
    "\n",
    "source_sentences = helper.load_data(source_path)\n",
    "target_sentences = helper.load_data(target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bsaqq',\n",
       " 'npy',\n",
       " 'lbwuj',\n",
       " 'bqv',\n",
       " 'kial',\n",
       " 'tddam',\n",
       " 'edxpjpg',\n",
       " 'nspv',\n",
       " 'huloz',\n",
       " '']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_sentences[:50].split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abqqs',\n",
       " 'npy',\n",
       " 'bjluw',\n",
       " 'bqv',\n",
       " 'aikl',\n",
       " 'addmt',\n",
       " 'degjppx',\n",
       " 'npsv',\n",
       " 'hlouz',\n",
       " '']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_sentences[:50].split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example source sequence\n",
      "[[5, 27, 9, 13, 13], [20, 14, 18], [15, 5, 24, 12, 28]]\n",
      "\n",
      "\n",
      "Example target sequence\n",
      "[[9, 5, 13, 13, 27], [20, 14, 18], [5, 28, 15, 12, 24]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_character_vocab(data):\n",
    "    special_words = ['<pad>','<unk>','<s>','</s>']\n",
    "    set_words = set([character for line in data.split('\\n') for character in line])\n",
    "    int_to_vocab = {word_i:word for word_i, word in enumerate(special_words + list(set_words))}\n",
    "    vocab_to_int = {word:word_i for word_i, word in int_to_vocab.items()}\n",
    "    return int_to_vocab, vocab_to_int\n",
    "    \n",
    "# Build int2letter and letter2int dicts\n",
    "source_int_to_letter, source_letter_to_int = extract_character_vocab(source_sentences)\n",
    "target_int_to_letter, target_letter_to_int = extract_character_vocab(target_sentences)\n",
    "\n",
    "source_letter_ids = [[source_letter_to_int.get(letter, source_letter_to_int['<unk>']) for letter in line] for line in source_sentences.split('\\n')]\n",
    "target_letter_ids = [[target_letter_to_int.get(letter, target_letter_to_int['<unk>']) for letter in line] for line in target_sentences.split('\\n')]\n",
    "\n",
    "print(\"Example source sequence\")\n",
    "print(source_letter_ids[:3])\n",
    "print(\"\\n\")\n",
    "print(\"Example target sequence\")\n",
    "print(target_letter_ids[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence Length\n",
      "7\n",
      "\n",
      "\n",
      "Input sequence example\n",
      "[[5, 27, 9, 13, 13, 0, 0], [20, 14, 18, 0, 0, 0, 0], [15, 5, 24, 12, 28, 0, 0]]\n",
      "\n",
      "\n",
      "Target sequence example\n",
      "[[9, 5, 13, 13, 27, 0, 0], [20, 14, 18, 0, 0, 0, 0], [5, 28, 15, 12, 24, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "def pad_id_sequences(source_ids, source_letter_to_int, target_ids, target_letter_to_int, sequence_length):\n",
    "    new_source_ids = [sentence + [source_letter_to_int['<pad>']]*(sequence_length - len(sentence)) for sentence in source_ids]\n",
    "    new_target_ids = [sentence + [target_letter_to_int['<pad>']]* (sequence_length-len(sentence)) for sentence in target_ids]\n",
    "    return new_source_ids, new_target_ids\n",
    "    \n",
    "sequence_length = max([len(sentence) for sentence in source_letter_ids]+[len(sentence) for sentence in target_letter_ids])\n",
    "source_ids, target_ids = pad_id_sequences(source_letter_ids, source_letter_to_int, target_letter_ids, target_letter_to_int, sequence_length)\n",
    "\n",
    "print(\"Sequence Length\")\n",
    "print(sequence_length)\n",
    "print(\"\\n\")\n",
    "print(\"Input sequence example\")\n",
    "print(source_ids[:3])\n",
    "print(\"\\n\")\n",
    "print(\"Target sequence example\")\n",
    "print(target_ids[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version: 1.0.1\n"
     ]
    }
   ],
   "source": [
    "from distutils.version import LooseVersion\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'please use tensorflow version 1.0 or new'\n",
    "print('tensorflow version: {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 60\n",
    "batch_size = 128\n",
    "rnn_size = 50\n",
    "num_layers = 2\n",
    "encoding_embedding_size = 13\n",
    "decoding_embedding_size = 13\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_data = tf.placeholder(tf.int32, [batch_size, sequence_length])\n",
    "targets = tf.placeholder(tf.int32, [batch_size, sequence_length])\n",
    "learningRate = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source_vocab_size = len(source_letter_to_int)\n",
    "\n",
    "# Encoder embedding\n",
    "enc_embed_input = tf.contrib.layers.embed_sequence(input_data, source_vocab_size, encoding_embedding_size)\n",
    "\n",
    "# Encoder\n",
    "enc_cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.BasicLSTMCell(rnn_size)] * num_layers)\n",
    "_, enc_state = tf.nn.dynamic_rnn(enc_cell, enc_embed_input, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process decoding input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets\n",
      "[[ 0  1  2  3  4  5  6]\n",
      " [ 7  8  9 10 11 12 13]]\n",
      "\n",
      "\n",
      "Processed Decoding Input\n",
      "[[ 2  0  1  2  3  4  5]\n",
      " [ 2  7  8  9 10 11 12]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Process the input we'll feed to the decoder\n",
    "ending = tf.strided_slice(targets, [0, 0], [batch_size, -1], [1, 1])\n",
    "dec_input = tf.concat([tf.fill([batch_size, 1], target_letter_to_int['<s>']), ending], 1)\n",
    "\n",
    "demonstration_outputs = np.reshape(range(batch_size * sequence_length), (batch_size, sequence_length))\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "print(\"Targets\")\n",
    "print(demonstration_outputs[:2])\n",
    "print(\"\\n\")\n",
    "print(\"Processed Decoding Input\")\n",
    "print(sess.run(dec_input, {targets: demonstration_outputs})[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Variable/read:0\", shape=(30, 13), dtype=float32)\n",
      "Tensor(\"embedding_lookup:0\", shape=(128, 7, 13), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "target_vocab_size = len(target_letter_to_int)\n",
    "\n",
    "#decoding embedding\n",
    "dec_embedding = tf.Variable(tf.random_uniform([target_vocab_size, decoding_embedding_size]))\n",
    "print(dec_embedding)\n",
    "dec_embed_input = tf.nn.embedding_lookup(dec_embedding, dec_input)\n",
    "print(dec_embed_input)\n",
    "\n",
    "#decoder rnn\n",
    "dec_cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.BasicLSTMCell(rnn_size)]*num_layers)\n",
    "with tf.variable_scope('decoding') as decoding_scope:\n",
    "    #output layer\n",
    "    output_fn = lambda x: tf.contrib.layers.fully_connected(x, target_vocab_size, None, scope=decoding_scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
